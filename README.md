# Hi, I'm Brandon Trumble

Dedicated to building fast, efficient AI systems from scratch.

Designing optimized C++/CUDA architectures and low-level machine learning tools.

![AI coding gif](https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExbW1xbW9sOHQ4ODlyNW5jOW83cGF0a25nNmF6YTU5N2lqM2RpbzV3NSZlcD12MV9naWZzX3NlYXJjaCZjdD1n/qgQUggAC3Pfv687qPC/giphy.gif)

---

## About Me

- Currently building: [Ada – C++/CUDA-powered Transformer Engine](https://github.com/bran7230/CPP-AND-CUDA-AI)
- Interested in: AI acceleration, GPU programming, neural network design, transformers
- Ask me about: C++, CUDA, FP16, matrix ops, softmax, tokenizer design, training pipelines
- Learning now: Backpropagation in CUDA, transformer scaling, memory optimization
- Contact me: brandon.ta.trumble@icloud.com  
- Portfolio: [GitHub Profile](https://github.com/bran7230)

---

## Tech Stack

### Languages  
C++ • Python • Java • JavaScript • HTML • CSS • SQL • Bash

### AI / Deep Learning  
CUDA • Tensor Cores • FP16 Arithmetic • Matrix Multiplication • Softmax • Backpropagation

### Tools & Platforms  
Git • Visual Studio • VSCode • GDB • CMake • Markdown

### Concepts  
Neural Networks • Transformer Architecture • Token Embeddings • Optimization & Benchmarking  
Manual Weight Updates • Gradient Descent • Forward/Backward Pass Design

---

## Selected Projects

- **Ada (C++ AI Engine)** – Transformer-based model built from scratch in C++/CUDA  
- **Tokenizer Generator** – Lightweight token ID mapping system used for embedding layers  
- **Softmax Benchmarker** – CUDA vs CPU softmax speed comparison with FP16 optimization

---

## Goals

- Scale Ada toward GPT-2 level performance  
- Build a full pipeline: tokenizer → embedding → transformer → inference  
- Translate Ada from C++ to pure C as a challenge project  
- Develop a lightweight web API for real-time model querying

---

Thanks for visiting. Feel free to explore my projects or reach out to collaborate.
