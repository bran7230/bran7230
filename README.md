<h1 align="center">Hi, I'm Brandon Trumble</h1>
<h3 align="center">AI Architect ‚Ä¢ CUDA Developer ‚Ä¢ Systems Optimizer</h3>

<p align="center">
  <img src="https://media.giphy.com/media/qgQUggAC3Pfv687qPC/giphy.gif" width="400" alt="AI Developer GIF" />
</p>

---

##  About Me

**Builder of AI from the ground up.**  
I specialize in creating custom transformer-based architectures using raw C++ and CUDA ‚Äî no frameworks, just logic, math, and performance.

- üîß **Currently Building:** [Syntari ‚Äì My Transformer AI Engine](https://github.com/bran7230/CPP-AND-CUDA-AI)
- üîç **Learning:** CUDA memory tuning, transformer scaling, GPT-level design
- üí¨ **Ask Me About:** C++, CUDA, matrix ops, FP16, tokenizer design, transformers
- üì´ **Contact:** brandonttrumble@gmail.com
- üåê **GitHub:** [github.com/bran7230](https://github.com/bran7230)

---

##  Tech Stack

| Languages            | AI/ML & Math                   | Tools & Platforms        |
|----------------------|--------------------------------|--------------------------|
| C++, Python, Java    | CUDA, FP16, Softmax, Backprop  | Git, VSCode, GDB |
| JavaScript, SQL, Bash| Matrix Ops, Embeddings         | Markdown, CLI Utilities  |

---

##  Concepts I Work With

- Manual weight updates (no frameworks)
- Transformer blocks, attention, and tokenization
- Gradient descent, forward/backward propagation
- GPU performance tuning and benchmarking
- Neural net math logic (dot, matmul, relu, softmax)

---

##  Featured Projects(All in my CUDA repo/Neural network C# repo)

### [Syntari](https://github.com/bran7230/CPP-AND-CUDA-AI)
> A fully custom GPT-like AI engine built with C++ and CUDA.  
Implements transformer architecture from scratch with optimized matrix math and token handling.

### [Tokenizer & Embedding Generator (NeuralNetwork c#)](https://github.com/bran7230/Neuralnetwork)
> A hand-crafted token ID mapping system with embedding support, written for speed and clarity.

### [CUDA vs CPU Softmax Benchmark (Syntari Ai)](https://github.com/bran7230/CPP-AND-CUDA-AI)
> Performance benchmarking suite that compares CPU softmax vs shared-memory CUDA + FP16 optimization.

---

##  Goals

- Scale Syntari to GPT-2 Medium or Large level  
- Build an end-to-end inference pipeline: tokenizer ‚Üí transformer ‚Üí output  
- Wrap the AI engine into a web API (C++ backend)  
- Eventually rewrite it all in pure C for performance challenge

---

<p align="center"><i>‚ÄúStart from scratch. Optimize everything. Understand deeply.‚Äù</i></p>
